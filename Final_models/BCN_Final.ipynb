{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BCN-first_SSTrun.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"nmqmdv3uyGlY","colab_type":"text"},"cell_type":"markdown","source":["# BCN model"]},{"metadata":{"id":"gGOB6VZhyHbR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":588},"outputId":"e0f15f3e-7e12-43a6-d6cf-80d29befdbb9","executionInfo":{"status":"ok","timestamp":1546253128731,"user_tz":-60,"elapsed":33511,"user":{"displayName":"Uppahhh","photoUrl":"","userId":"09355873330880409745"}}},"cell_type":"code","source":["!pip install numpy\n","!pip install torchtext\n","!pip install torch\n","!pip install sklearn\n","!pip install bokeh\n","!pip install matplotlib"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.14.6)\n","Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (0.3.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.14.6)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.0.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.18.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.28.1)\n","Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.6)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2018.11.29)\n","Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.22)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.0)\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.20.1)\n","Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.14.6)\n","Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.1.0)\n","Requirement already satisfied: bokeh in /usr/local/lib/python3.6/dist-packages (1.0.2)\n","Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.6/dist-packages (from bokeh) (1.11.0)\n","Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from bokeh) (3.13)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from bokeh) (2.5.3)\n","Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.6/dist-packages (from bokeh) (2.10)\n","Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from bokeh) (1.14.6)\n","Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.6/dist-packages (from bokeh) (4.0.0)\n","Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.6/dist-packages (from bokeh) (18.0)\n","Requirement already satisfied: tornado>=4.3 in /usr/local/lib/python3.6/dist-packages (from bokeh) (4.5.3)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7->bokeh) (1.1.0)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.0->bokeh) (0.46)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=16.8->bokeh) (2.3.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (2.1.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n","Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.14.6)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.3.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2018.7)\n"],"name":"stdout"}]},{"metadata":{"id":"6RPASbzjyGla","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":47},"outputId":"5c153028-aa3b-4c69-b778-d3d45486938e","executionInfo":{"status":"ok","timestamp":1546451695856,"user_tz":-60,"elapsed":6237,"user":{"displayName":"Uppahhh","photoUrl":"","userId":"09355873330880409745"}}},"cell_type":"code","source":["import numpy as np\n","\n","from torchtext import data\n","from torchtext import datasets\n","from torchtext.vocab import Vectors\n","\n","import torch\n","from torch.autograd import Variable, Function\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.nn import Linear\n","from torch.nn.functional import softmax, relu, tanh\n","from torchtext.vocab import Vectors, GloVe, CharNGram, FastText\n","from torch.nn.utils.rnn import pack_padded_sequence as pack\n","from torch.nn.utils.rnn import pad_packed_sequence as unpack\n","from torch.nn.utils.rnn import pad_sequence as pad\n","\n","import matplotlib.pyplot as plt\n","\n","\n","from sklearn.manifold import TSNE\n","\n","from bokeh.plotting import figure, ColumnDataSource\n","from bokeh.models import HoverTool\n","from bokeh.io import output_notebook, show, push_notebook\n","output_notebook()\n"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div class=\"bk-root\">\n","        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n","        <span id=\"1001\">Loading BokehJS ...</span>\n","    </div>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["\n","(function(root) {\n","  function now() {\n","    return new Date();\n","  }\n","\n","  var force = true;\n","\n","  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n","    root._bokeh_onload_callbacks = [];\n","    root._bokeh_is_loading = undefined;\n","  }\n","\n","  var JS_MIME_TYPE = 'application/javascript';\n","  var HTML_MIME_TYPE = 'text/html';\n","  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n","  var CLASS_NAME = 'output_bokeh rendered_html';\n","\n","  /**\n","   * Render data to the DOM node\n","   */\n","  function render(props, node) {\n","    var script = document.createElement(\"script\");\n","    node.appendChild(script);\n","  }\n","\n","  /**\n","   * Handle when an output is cleared or removed\n","   */\n","  function handleClearOutput(event, handle) {\n","    var cell = handle.cell;\n","\n","    var id = cell.output_area._bokeh_element_id;\n","    var server_id = cell.output_area._bokeh_server_id;\n","    // Clean up Bokeh references\n","    if (id != null && id in Bokeh.index) {\n","      Bokeh.index[id].model.document.clear();\n","      delete Bokeh.index[id];\n","    }\n","\n","    if (server_id !== undefined) {\n","      // Clean up Bokeh references\n","      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n","      cell.notebook.kernel.execute(cmd, {\n","        iopub: {\n","          output: function(msg) {\n","            var id = msg.content.text.trim();\n","            if (id in Bokeh.index) {\n","              Bokeh.index[id].model.document.clear();\n","              delete Bokeh.index[id];\n","            }\n","          }\n","        }\n","      });\n","      // Destroy server and session\n","      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n","      cell.notebook.kernel.execute(cmd);\n","    }\n","  }\n","\n","  /**\n","   * Handle when a new output is added\n","   */\n","  function handleAddOutput(event, handle) {\n","    var output_area = handle.output_area;\n","    var output = handle.output;\n","\n","    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n","    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n","      return\n","    }\n","\n","    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n","\n","    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n","      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n","      // store reference to embed id on output_area\n","      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n","    }\n","    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n","      var bk_div = document.createElement(\"div\");\n","      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n","      var script_attrs = bk_div.children[0].attributes;\n","      for (var i = 0; i < script_attrs.length; i++) {\n","        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n","      }\n","      // store reference to server id on output_area\n","      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n","    }\n","  }\n","\n","  function register_renderer(events, OutputArea) {\n","\n","    function append_mime(data, metadata, element) {\n","      // create a DOM node to render to\n","      var toinsert = this.create_output_subarea(\n","        metadata,\n","        CLASS_NAME,\n","        EXEC_MIME_TYPE\n","      );\n","      this.keyboard_manager.register_events(toinsert);\n","      // Render to node\n","      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n","      render(props, toinsert[toinsert.length - 1]);\n","      element.append(toinsert);\n","      return toinsert\n","    }\n","\n","    /* Handle when an output is cleared or removed */\n","    events.on('clear_output.CodeCell', handleClearOutput);\n","    events.on('delete.Cell', handleClearOutput);\n","\n","    /* Handle when a new output is added */\n","    events.on('output_added.OutputArea', handleAddOutput);\n","\n","    /**\n","     * Register the mime type and append_mime function with output_area\n","     */\n","    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n","      /* Is output safe? */\n","      safe: true,\n","      /* Index of renderer in `output_area.display_order` */\n","      index: 0\n","    });\n","  }\n","\n","  // register the mime type if in Jupyter Notebook environment and previously unregistered\n","  if (root.Jupyter !== undefined) {\n","    var events = require('base/js/events');\n","    var OutputArea = require('notebook/js/outputarea').OutputArea;\n","\n","    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n","      register_renderer(events, OutputArea);\n","    }\n","  }\n","\n","  \n","  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n","    root._bokeh_timeout = Date.now() + 5000;\n","    root._bokeh_failed_load = false;\n","  }\n","\n","  var NB_LOAD_WARNING = {'data': {'text/html':\n","     \"<div style='background-color: #fdd'>\\n\"+\n","     \"<p>\\n\"+\n","     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n","     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n","     \"</p>\\n\"+\n","     \"<ul>\\n\"+\n","     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n","     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n","     \"</ul>\\n\"+\n","     \"<code>\\n\"+\n","     \"from bokeh.resources import INLINE\\n\"+\n","     \"output_notebook(resources=INLINE)\\n\"+\n","     \"</code>\\n\"+\n","     \"</div>\"}};\n","\n","  function display_loaded() {\n","    var el = document.getElementById(\"1001\");\n","    if (el != null) {\n","      el.textContent = \"BokehJS is loading...\";\n","    }\n","    if (root.Bokeh !== undefined) {\n","      if (el != null) {\n","        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n","      }\n","    } else if (Date.now() < root._bokeh_timeout) {\n","      setTimeout(display_loaded, 100)\n","    }\n","  }\n","\n","\n","  function run_callbacks() {\n","    try {\n","      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n","    }\n","    finally {\n","      delete root._bokeh_onload_callbacks\n","    }\n","    console.info(\"Bokeh: all callbacks have finished\");\n","  }\n","\n","  function load_libs(js_urls, callback) {\n","    root._bokeh_onload_callbacks.push(callback);\n","    if (root._bokeh_is_loading > 0) {\n","      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n","      return null;\n","    }\n","    if (js_urls == null || js_urls.length === 0) {\n","      run_callbacks();\n","      return null;\n","    }\n","    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n","    root._bokeh_is_loading = js_urls.length;\n","    for (var i = 0; i < js_urls.length; i++) {\n","      var url = js_urls[i];\n","      var s = document.createElement('script');\n","      s.src = url;\n","      s.async = false;\n","      s.onreadystatechange = s.onload = function() {\n","        root._bokeh_is_loading--;\n","        if (root._bokeh_is_loading === 0) {\n","          console.log(\"Bokeh: all BokehJS libraries loaded\");\n","          run_callbacks()\n","        }\n","      };\n","      s.onerror = function() {\n","        console.warn(\"failed to load library \" + url);\n","      };\n","      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n","      document.getElementsByTagName(\"head\")[0].appendChild(s);\n","    }\n","  };var element = document.getElementById(\"1001\");\n","  if (element == null) {\n","    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n","    return false;\n","  }\n","\n","  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.2.min.js\"];\n","\n","  var inline_js = [\n","    function(Bokeh) {\n","      Bokeh.set_log_level(\"info\");\n","    },\n","    \n","    function(Bokeh) {\n","      \n","    },\n","    function(Bokeh) {\n","      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n","      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n","      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n","      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n","      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n","      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n","    }\n","  ];\n","\n","  function run_inline_js() {\n","    \n","    if ((root.Bokeh !== undefined) || (force === true)) {\n","      for (var i = 0; i < inline_js.length; i++) {\n","        inline_js[i].call(root, root.Bokeh);\n","      }if (force === true) {\n","        display_loaded();\n","      }} else if (Date.now() < root._bokeh_timeout) {\n","      setTimeout(run_inline_js, 100);\n","    } else if (!root._bokeh_failed_load) {\n","      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n","      root._bokeh_failed_load = true;\n","    } else if (force !== true) {\n","      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n","      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n","    }\n","\n","  }\n","\n","  if (root._bokeh_is_loading === 0) {\n","    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n","    run_inline_js();\n","  } else {\n","    load_libs(js_urls, function() {\n","      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n","      run_inline_js();\n","    });\n","  }\n","}(window));"],"application/vnd.bokehjs_load.v0+json":"\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.2.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.2.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.2.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.2.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"},"metadata":{"tags":[]}}]},{"metadata":{"id":"EX5t32N6yGlh","colab_type":"code","colab":{}},"cell_type":"code","source":["use_cuda = torch.cuda.is_available()\n","\n","def get_variable(x):\n","    \"\"\" Converts tensors to cuda, if available. \"\"\"\n","    if use_cuda:\n","        return x.cuda()\n","    return x\n","\n","def get_numpy(x):\n","    \"\"\" Get numpy array for both cuda and not. \"\"\"\n","    if use_cuda:\n","        return x.cpu().data.numpy()\n","    return x.data.numpy()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dpYjRn4TyGln","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","class Maxout(Function):\n","\n","    # Note that both forward and backward are @staticmethods\n","    @staticmethod\n","    # bias is an optional argument\n","    def forward(ctx, input):\n","        x = input\n","        max_out=4    #Maxout Parameter\n","        kernels = x.shape[1]  # to get how many kernels/output\n","        feature_maps = int(kernels / max_out)\n","        out_shape = (x.shape[0], feature_maps, max_out)\n","        x= x.view(out_shape)\n","        y, indices = torch.max(x[:, :, :], 2)\n","        ctx.save_for_backward(input)\n","        ctx.indices=indices\n","        ctx.max_out=max_out\n","        return y\n","\n","    # This function has only a single output, so it gets only one gradient\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        input1,indices,max_out= ctx.saved_variables[0],Variable(ctx.indices),ctx.max_out\n","        input=input1.clone()\n","        for i in range(max_out):\n","            a0=indices==i\n","            input[:,i:input.data.shape[1]:max_out]=a0.float()*grad_output\n","      \n","\n","        return input"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3lFMxdu5yGlq","colab_type":"text"},"cell_type":"markdown","source":["## SST"]},{"metadata":{"id":"ZRQsVM2ByGlr","colab_type":"code","colab":{}},"cell_type":"code","source":["TEXT = data.Field(sequential=True,include_lengths=True)\n","LABEL = data.Field(sequential=False)\n","\n","train_set, validation_set, test_set = datasets.SST.splits(TEXT,\n","                                                          LABEL,\n","                                                          fine_grained=False,\n","                                                          train_subtrees=True,\n","                                                          filter_pred=lambda ex: ex.label != 'neutral')"],"execution_count":0,"outputs":[]},{"metadata":{"scrolled":true,"id":"81a7T4LuyGlv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"a4ede0ac-23eb-446f-c2c5-e358de8cc8bf","executionInfo":{"status":"ok","timestamp":1546421519412,"user_tz":-60,"elapsed":2338,"user":{"displayName":"Uppahhh","photoUrl":"","userId":"09355873330880409745"}}},"cell_type":"code","source":["print('train.fields', train_set.fields)\n","print('len(train)', len(train_set))\n","print('vars(train[0])', vars(train_set[0]))\n","print()\n","print('Example 2', vars(train_set[17]))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["train.fields {'text': <torchtext.data.field.Field object at 0x7f8ed1d3ed30>, 'label': <torchtext.data.field.Field object at 0x7f8ed1d3ec18>}\n","len(train) 98794\n","vars(train[0]) {'text': ['The', 'Rock', 'is', 'destined', 'to', 'be', 'the', '21st', 'Century', \"'s\", 'new', '``', 'Conan', \"''\", 'and', 'that', 'he', \"'s\", 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'Arnold', 'Schwarzenegger', ',', 'Jean-Claud', 'Van', 'Damme', 'or', 'Steven', 'Segal', '.'], 'label': 'positive'}\n","\n","Example 2 {'text': ['The', 'gorgeously', 'elaborate', 'continuation', 'of', '``', 'The', 'Lord', 'of', 'the', 'Rings', \"''\", 'trilogy', 'is', 'so', 'huge', 'that', 'a', 'column', 'of', 'words', 'can', 'not', 'adequately', 'describe', 'co-writer\\\\/director', 'Peter', 'Jackson', \"'s\", 'expanded', 'vision', 'of', 'J.R.R.', 'Tolkien', \"'s\", 'Middle-earth', '.'], 'label': 'positive'}\n"],"name":"stdout"}]},{"metadata":{"id":"RopJ9duWyGlz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"e5993111-afca-453e-c291-8a17e242f265","executionInfo":{"status":"ok","timestamp":1546421529446,"user_tz":-60,"elapsed":7250,"user":{"displayName":"Uppahhh","photoUrl":"","userId":"09355873330880409745"}}},"cell_type":"code","source":["# build the vocabulary\n","url = 'https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.simple.vec'\n","#url = 'http://nlp.stanford.edu/data/glove.840B.300d.zip'\n","#TEXT.build_vocab(train_set, max_size=None, vectors=Vectors('wiki.simple.vec', url=url))\n","TEXT.build_vocab(train_set,vectors=GloVe(name='840B',dim='300'))\n","\n","LABEL.build_vocab(train_set)\n","# print vocab information\n","print('len(TEXT.vocab)', len(TEXT.vocab))\n","print('TEXT.vocab.vectors.size()', TEXT.vocab.vectors.size())\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["len(TEXT.vocab) 18003\n","TEXT.vocab.vectors.size() torch.Size([18003, 300])\n"],"name":"stdout"}]},{"metadata":{"id":"1ghOY4aTyGl3","colab_type":"code","colab":{}},"cell_type":"code","source":["# make iterator for splits\n","train_iter, val_iter, test_iter = data.Iterator.splits(\n","    (train_set, validation_set, test_set), batch_size=32, sort_key=lambda x: len(x.text),sort_within_batch=True, repeat=False)\n","\n","\n","# print batch information\n","batchsst = next(iter(train_iter))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"esIce8YRyGl6","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"ebZEiBNFyGl9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":252},"outputId":"03263769-8234-49d6-adcf-ea8da4a09515","executionInfo":{"status":"ok","timestamp":1546426128757,"user_tz":-60,"elapsed":1907,"user":{"displayName":"Uppahhh","photoUrl":"","userId":"09355873330880409745"}}},"cell_type":"code","source":["embedding_dim = TEXT.vocab.vectors.size()[1]\n","num_embeddings = TEXT.vocab.vectors.size()[0]\n","num_classes = len(LABEL.vocab.itos)\n","\n","dropout_rate = 0.4\n","\n","input_dim = 100\n","\n","con_dim = 200\n","\n","hidden_dim = 300\n","\n","def dyn_Linear (in_features,out_features):\n","    return Linear(in_features = in_features, out_features = out_features, bias = False)\n","def dyn_batchnorm(num_features):\n","    return nn.BatchNorm1d(num_features)\n","\n","# build the model\n","class BCNNet(nn.Module):\n","\n","    def __init__(self):\n","        super(BCNNet, self).__init__()\n","        self.embeddings = nn.Embedding(num_embeddings, embedding_dim)\n","        # use pretrained embeddings\n","        self.embeddings.weight.data.copy_(TEXT.vocab.vectors)\n","        \n","        # The ReLu activtion layer\n","        self.input = Linear(in_features = embedding_dim,\n","                            out_features = embedding_dim,\n","                             bias = False)\n","        \n","        # bilstm encoder\n","        self.bilstm_enc = nn.LSTM(input_size = embedding_dim,\n","                                  hidden_size = embedding_dim,\n","                                  batch_first = False,\n","                                  bidirectional = True)\n","        \n","        # bilstm integrator\n","        self.bilstm_int = nn.LSTM(input_size = embedding_dim*3*2,\n","                                  hidden_size = embedding_dim,\n","                                  batch_first = False,\n","                                  bidirectional = True)\n","        \n","        self.attnx = Linear(in_features=embedding_dim*2,\n","                              out_features = embedding_dim*2)\n","        self.attny = Linear(in_features=embedding_dim*2,\n","                              out_features = embedding_dim*2)\n","        \n","        #Pooling\n","        self.maxpool = nn.MaxPool1d(kernel_size = embedding_dim)\n","        self.avgpool = nn.AvgPool1d(kernel_size = embedding_dim)\n","                \n","        # maxout layer  \n","        self.batch = nn.BatchNorm1d(num_features=8)\n","        \n","        self.maxout = Linear(in_features = 8,\n","                                out_features = 8*2*2)\n","        \n","        \n","        self.mo1 = Maxout.apply\n","        self.mo2 = Maxout.apply\n","        self.mo3 = Maxout.apply\n","        \n","        self.out = Linear(in_features = 8,\n","                            out_features = num_classes,\n","                             bias = False)\n","\n","        self.drop = nn.Dropout(p = dropout_rate)\n","        \n","    def forward(self, x, y):\n","        out = {}\n","        x_text, x_len = x\n","        y_text, y_len = y\n","        \n","        # Sorting tensors\n","        x_len, idx_sort = np.sort(x_len)[::-1],np.argsort(-x_len)\n","        x_text = x_text.index_select(1,torch.LongTensor(idx_sort))\n","        y_len, idx_sort = np.sort(y_len)[::-1],np.argsort(-y_len)\n","        y_text = y_text.index_select(1,torch.LongTensor(idx_sort))\n","        \n","        # Embedding\n","        x = self.embeddings(x_text)\n","        y = self.embeddings(y_text)\n","        \n","        # Relu\n","        x = relu(self.input(x))\n","        y = relu(self.input(y))\n","\n","        # Encoder\n","        # Packing padded sequences to max_length\n","        packed_x = pack(x,x_len.copy(), batch_first = False)\n","        packed_y = pack(y,y_len.copy(), batch_first = False)\n","        # biLSTM\n","        x, hidenc_fx = self.bilstm_enc(x)\n","        y, hidenc_fy = self.bilstm_enc(y)\n","        xt = hidenc_fx[0]\n","        yt = hidenc_fy[0]\n","        # Unsorting\n","        idx_unsort = np.argsort(idx_sort)\n","        xt1 = xt[0].index_select(0,torch.LongTensor(idx_unsort))\n","        xt2 = xt[1].index_select(0,torch.LongTensor(idx_unsort))\n","\n","        yt1 = yt[0].index_select(0,torch.LongTensor(idx_unsort))\n","        yt2 = yt[1].index_select(0,torch.LongTensor(idx_unsort))\n","        \n","\n","        X = torch.cat((xt1,xt2),1) \n","        Y = torch.cat((yt1,yt2),1)\n","        X = X.view(1,X.size()[0],X.size()[1])\n","        Y = Y.view(1,Y.size()[0],Y.size()[1])\n","        \n","        # Biattention\n","        #dim 1 = len, dim 2 = dim, and they are swaped so we can multiply the matrices\n","        A = torch.matmul(X, Y.transpose(1,2)) # A = X * Y^T  x = bs, len, dim, y^T = bs,dim, len\n","        A_x = softmax(A, dim=2) # A_x = softmax(A)\n","        A_y = softmax(A.transpose(1,2), dim=2) # A_y = softmax(A^T)\n","        C_x = torch.matmul(A_x.transpose(1,2), X) # C_x = A_x^T * X \n","        C_y = torch.matmul(A_y.transpose(1,2), Y) # C_y = A_y^T * Y\n","        \n","        # Integrator\n","        # input for integrator bilstm\n","        \n","        x = torch.cat((X, X-C_y, torch.mul(X, C_y)), 2) # Concat([X; X-C_y; X.C_y])\n","        y = torch.cat((Y, Y-C_x, torch.mul(Y, C_x)), 2) # Concat([Y; Y-C_x; Y.C_x]\n","        # X_|y = biLSTM(%), Y|x = biLSTM(%)\n","        \n","            \n","        X_y, hidint_x = self.bilstm_int(x)\n","        Y_x, hidint_y = self.bilstm_int(y)\n","        \n","        X_temp = hidint_x[0]\n","        X_temp = torch.cat((X_temp[0],X_temp[1]),1)\n","        hidint_x = X_temp.view(1,X_temp.size()[0],X_temp.size()[1])\n","        \n","        Y_temp = hidint_y[0]\n","        Y_temp = torch.cat((Y_temp[0],Y_temp[1]),1)\n","        hidint_y = Y_temp.view(1,Y_temp.size()[0],Y_temp.size()[1])\n","       \n","        X_y = hidint_x\n","        Y_x = hidint_y\n","        \n","       \n","        \n","        # Pooling\n","        x_maxpool = self.maxpool(X_y)\n","        x_meanpool = self.avgpool(X_y)      \n","        x_minpool = X_y * -1\n","        x_minpool = self.maxpool(x_minpool)\n","        x_minpool = x_minpool * -1\n","        x_pool = torch.cat((x_maxpool, x_meanpool), 2)\n","       # print(x_pool.size())\n","        \n","      #  print(x_pool.size())\n","        \n","        y_maxpool = self.maxpool(Y_x)\n","        y_meanpool = self.avgpool(Y_x)\n","        y_minpool = Y_x * -1\n","        y_minpool = self.maxpool(y_minpool)\n","        y_minpool = y_minpool * -1\n","        y_pool = torch.cat((y_maxpool, y_meanpool), 2)\n","        \n","        # Maxout layer\n","        # And batchnormilization\n","        # Joined representations is the concatination of x_pool and y_pool\n","        joined = torch.cat((x_pool, y_pool), 2)\n","        joined = torch.squeeze(joined,0)\n","\n","        joined = self.mo1(self.maxout(joined))\n","        \n","        joined = self.mo2(self.maxout(joined))\n","        \n","        joined = self.mo3(self.maxout(joined))\n","        joined = self.batch(joined)\n","        \n","        # 3rd maxout layer will be output\n","        out['out'] = softmax(self.out(joined), dim=1)\n","        return out\n","\n","net = BCNNet()\n","print(net)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["BCNNet(\n","  (embeddings): Embedding(18003, 300)\n","  (input): Linear(in_features=300, out_features=300, bias=False)\n","  (bilstm_enc): LSTM(300, 300, bidirectional=True)\n","  (bilstm_int): LSTM(1800, 300, bidirectional=True)\n","  (attnx): Linear(in_features=600, out_features=600, bias=True)\n","  (attny): Linear(in_features=600, out_features=600, bias=True)\n","  (maxpool): MaxPool1d(kernel_size=300, stride=300, padding=0, dilation=1, ceil_mode=False)\n","  (avgpool): AvgPool1d(kernel_size=(300,), stride=(300,), padding=(0,))\n","  (batch): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (maxout): Linear(in_features=8, out_features=32, bias=True)\n","  (out): Linear(in_features=8, out_features=3, bias=False)\n","  (drop): Dropout(p=0.4)\n",")\n"],"name":"stdout"}]},{"metadata":{"id":"ClFaBIR5yGmB","colab_type":"code","colab":{}},"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(), lr=0.0003,amsgrad=True,weight_decay=0.00001)\n","\n","def accuracy(ys, ts):\n","    # making a one-hot encoded vector of correct (1) and incorrect (0) predictions\n","    correct_prediction = torch.eq(torch.max(ys, 1)[1], ts)\n","    # averaging the one-hot encoded vector\n","    return torch.mean(correct_prediction.float())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"81_utpkWyGmF","colab_type":"text"},"cell_type":"markdown","source":["## TRAINING BCN WITH SST"]},{"metadata":{"scrolled":true,"id":"abgbzBiWyGmF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1613},"outputId":"ad569d90-064d-46df-ff09-4ee207936eae","executionInfo":{"status":"ok","timestamp":1546448097298,"user_tz":-60,"elapsed":182396,"user":{"displayName":"Uppahhh","photoUrl":"","userId":"09355873330880409745"}}},"cell_type":"code","source":["eval_every = 500\n","log_every = 200\n","\n","train_loss, train_accs, train_iter_list = [], [], []\n","train_loss_list, train_accs_list = [],[]\n","val_loss_list, val_accs_list, val_iter_list = [],[], []\n","\n","\n","max_acc = 0\n","max_acc_idx = 0\n","epochs = 1\n","reached_max = False\n","\n","net.train()\n","while reached_max == False:\n","    print(\"EPOCH NR: \" + str(epochs))\n","    for i, batch in enumerate(train_iter):\n","        if i % eval_every == 0:\n","            net.eval()\n","            val_losses, val_accs, val_lengths = 0, 0, 0\n","      #  val_meta = {'label_idx': [], 'sentences': [], 'labels': []}\n","            for val_batch in val_iter:\n","                output = net(val_batch.text,val_batch.text)\n","            # batches sizes might vary, which is why we cannot just mean the batch's loss\n","            # we multiply the loss and accuracies with the batch's size,\n","            # to later divide by the total size\n","                val_losses += criterion(output['out'], val_batch.label) * val_batch.batch_size\n","                val_accs += accuracy(output['out'], val_batch.label) * val_batch.batch_size\n","                val_lengths += val_batch.batch_size\n","            \n","\n","        \n","        # divide by the total accumulated batch sizes\n","            val_losses /= val_lengths\n","            val_accs /= val_lengths\n","        \n","            val_loss_list.append(get_numpy(val_losses))\n","            val_accs_list.append(get_numpy(val_accs))\n","            val_iter_list.append(i)\n","        \n","            print(\"valid, it: {} loss: {:.2f} accs: {:.2f}\\n\".format(i, get_numpy(val_losses), get_numpy(val_accs)))\n","        #update_plot(val_meta, 'bow', tsne_plot)\n","        \n","            net.train()\n","    \n","        output = net(batch.text,batch.text)\n","        batch_loss = criterion(output['out'], batch.label)\n","    \n","        train_loss.append(get_numpy(batch_loss))\n","        train_accs.append(get_numpy(accuracy(output['out'], batch.label)))\n"," \n","    \n","        optimizer.zero_grad()\n","        batch_loss.backward()\n","        nn.utils.clip_grad_norm_(net.parameters(),max_norm=5)\n","        optimizer.step()\n","    \n","        if i % log_every == 0:        \n","            print(\"train, it: {} loss: {:.2f} accs: {:.2f}\".format(i, \n","                                                               np.mean(train_loss), \n","                                                               np.mean(train_accs)))\n","        # reset\n","            train_loss_list.append(np.mean(train_loss))\n","            train_accs_list.append(np.mean(train_accs))    \n","            train_iter_list.append(i)\n","            train_loss, train_accs = [], []\n","    if max(val_accs_list[max_acc_idx:len(val_accs_list)]) > max_acc:\n","        max_acc = max(val_accs_list[max_acc_idx:len(val_accs_list)])\n","        max_acc_idx = np.argmax(max(val_accs_list[max_acc_idx:len(val_accs_list)]))\n","    else:\n","        print(\"Maximum validation accuracy: \" + str(max_acc))\n","        reached_max = True\n","        break\n","    epochs += 1"],"execution_count":18,"outputs":[{"output_type":"stream","text":["EPOCH NR: 1\n","valid, it: 0 loss: 1.13 accs: 0.00\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: 'saved_variables' is deprecated; use 'saved_tensors'\n"],"name":"stderr"},{"output_type":"stream","text":["train, it: 0 loss: 1.10 accs: 0.38\n","train, it: 200 loss: 0.98 accs: 0.76\n","train, it: 400 loss: 0.86 accs: 0.86\n","valid, it: 500 loss: 0.86 accs: 0.79\n","\n","train, it: 600 loss: 0.79 accs: 0.87\n","train, it: 800 loss: 0.74 accs: 0.88\n","valid, it: 1000 loss: 0.77 accs: 0.80\n","\n","train, it: 1000 loss: 0.72 accs: 0.88\n","train, it: 1200 loss: 0.70 accs: 0.88\n","train, it: 1400 loss: 0.70 accs: 0.87\n","valid, it: 1500 loss: 0.78 accs: 0.78\n","\n","train, it: 1600 loss: 0.68 accs: 0.88\n","train, it: 1800 loss: 0.68 accs: 0.89\n","valid, it: 2000 loss: 0.76 accs: 0.80\n","\n","train, it: 2000 loss: 0.67 accs: 0.90\n","train, it: 2200 loss: 0.66 accs: 0.90\n","train, it: 2400 loss: 0.66 accs: 0.90\n","valid, it: 2500 loss: 0.78 accs: 0.77\n","\n","train, it: 2600 loss: 0.65 accs: 0.90\n","train, it: 2800 loss: 0.65 accs: 0.90\n","valid, it: 3000 loss: 0.77 accs: 0.78\n","\n","train, it: 3000 loss: 0.66 accs: 0.89\n","EPOCH NR: 2\n","valid, it: 0 loss: 0.76 accs: 0.79\n","\n","train, it: 0 loss: 0.66 accs: 0.90\n","train, it: 200 loss: 0.64 accs: 0.92\n","train, it: 400 loss: 0.64 accs: 0.92\n","valid, it: 500 loss: 0.76 accs: 0.79\n","\n","train, it: 600 loss: 0.63 accs: 0.92\n","train, it: 800 loss: 0.64 accs: 0.91\n","valid, it: 1000 loss: 0.75 accs: 0.80\n","\n","train, it: 1000 loss: 0.64 accs: 0.91\n","train, it: 1200 loss: 0.64 accs: 0.91\n","train, it: 1400 loss: 0.63 accs: 0.92\n","valid, it: 1500 loss: 0.75 accs: 0.80\n","\n","train, it: 1600 loss: 0.63 accs: 0.92\n","train, it: 1800 loss: 0.63 accs: 0.92\n","valid, it: 2000 loss: 0.74 accs: 0.81\n","\n","train, it: 2000 loss: 0.63 accs: 0.92\n","train, it: 2200 loss: 0.64 accs: 0.91\n","train, it: 2400 loss: 0.64 accs: 0.91\n","valid, it: 2500 loss: 0.73 accs: 0.82\n","\n","train, it: 2600 loss: 0.63 accs: 0.92\n","train, it: 2800 loss: 0.63 accs: 0.92\n","valid, it: 3000 loss: 0.75 accs: 0.80\n","\n","train, it: 3000 loss: 0.63 accs: 0.92\n","EPOCH NR: 3\n","valid, it: 0 loss: 0.73 accs: 0.82\n","\n","train, it: 0 loss: 0.64 accs: 0.91\n","train, it: 200 loss: 0.62 accs: 0.93\n","train, it: 400 loss: 0.61 accs: 0.94\n","valid, it: 500 loss: 0.75 accs: 0.80\n","\n","train, it: 600 loss: 0.63 accs: 0.92\n","train, it: 800 loss: 0.62 accs: 0.93\n","valid, it: 1000 loss: 0.74 accs: 0.81\n","\n","train, it: 1000 loss: 0.62 accs: 0.93\n","train, it: 1200 loss: 0.63 accs: 0.92\n","train, it: 1400 loss: 0.63 accs: 0.93\n","valid, it: 1500 loss: 0.74 accs: 0.81\n","\n","train, it: 1600 loss: 0.63 accs: 0.93\n","train, it: 1800 loss: 0.62 accs: 0.93\n","valid, it: 2000 loss: 0.73 accs: 0.82\n","\n","train, it: 2000 loss: 0.62 accs: 0.93\n","train, it: 2200 loss: 0.62 accs: 0.93\n","train, it: 2400 loss: 0.62 accs: 0.93\n","valid, it: 2500 loss: 0.75 accs: 0.80\n","\n","train, it: 2600 loss: 0.62 accs: 0.93\n","train, it: 2800 loss: 0.62 accs: 0.93\n","valid, it: 3000 loss: 0.75 accs: 0.79\n","\n","train, it: 3000 loss: 0.62 accs: 0.93\n","Maximum validation accuracy: 0.81880736\n"],"name":"stdout"}]},{"metadata":{"id":"G-qzu4_lyGmK","colab_type":"code","colab":{}},"cell_type":"code","source":["for i in range(int(len(train_iter_list)/(epochs)),len(train_iter_list)):\n","    if train_iter_list[i] == 0:\n","        train_iter_list[i] = train_iter_list[i-1]+1\n","        continue\n","    else:\n","        train_iter_list[i] = train_iter_list[i-1] + log_every\n","\n","\n","for i in range(int(len(val_iter_list)/epochs),len(val_iter_list)):\n","    if val_iter_list[i] == 0:\n","        val_iter_list[i] =val_iter_list[i-1]+1\n","        continue\n","    else:\n","        val_iter_list[i] = val_iter_list[i-1] + eval_every"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cKlURY90yGmP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":265},"outputId":"7c6f67bf-8866-43c5-f03f-c6b758c912d0","executionInfo":{"status":"ok","timestamp":1546448098924,"user_tz":-60,"elapsed":32264,"user":{"displayName":"Uppahhh","photoUrl":"","userId":"09355873330880409745"}}},"cell_type":"code","source":["fig = plt.figure(figsize=(12,4))\n","plt.subplot(1, 2, 1)\n","plt.plot(train_iter_list, train_loss_list, label='train_loss')\n","plt.plot(val_iter_list, val_loss_list, label='valid_loss')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(train_iter_list, train_accs_list, label='train_accs')\n","plt.plot(val_iter_list, val_accs_list, label='valid_accs')\n","plt.legend()\n","plt.show()"],"execution_count":20,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAsEAAAD4CAYAAAANWzs4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmvkAAAAASUVORK5CYII=\n","text/plain":["<matplotlib.figure.Figure at 0x7f8ec3944208>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"-o4z7S14yGmU","colab_type":"text"},"cell_type":"markdown","source":["## SNLI"]},{"metadata":{"scrolled":true,"id":"KE4vUDCdyGmV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":591},"outputId":"96a66bbd-d533-4ef9-e4ef-7a2be77136b8","executionInfo":{"status":"ok","timestamp":1546451768826,"user_tz":-60,"elapsed":57038,"user":{"displayName":"Uppahhh","photoUrl":"","userId":"09355873330880409745"}}},"cell_type":"code","source":["print(\"Run test on SNLI...\")\n","TEXT = datasets.nli.ParsedTextField()\n","LABEL = data.LabelField()\n","TREE = datasets.nli.ShiftReduceField()\n","\n","train, val, test = datasets.SNLI.splits(TEXT, LABEL, TREE)\n","\n","print(\"Fields:\", train.fields)\n","print(\"Number of examples:\\n\", len(train))\n","print(\"First Example instance:\\n\", vars(train[0]))\n","\n","url = 'https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.simple.vec'\n","TEXT.build_vocab(train, max_size=None, vectors=Vectors('wiki.simple.vec', url=url))\n","#TEXT.build_vocab(train,vectors=GloVe[name='840B',dim='300'])\n","LABEL.build_vocab(train)\n","\n","\n","train_iter, val_iter, test_iter = data.Iterator.splits((train, val, test), batch_size=64,repeat = False)\n","\n","\n","print(\"Test iters function\")\n","\n","batch = next(iter(train_iter))\n","print(\"Numericalize premises:\\n\", batch.premise)\n","print(\"Numericalize hypotheses:\\n\", batch.hypothesis)\n","print(\"Entailment labels:\\n\", batch.label)\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Run test on SNLI...\n","Fields: {'premise': <torchtext.datasets.nli.ParsedTextField object at 0x7fc84a575550>, 'premise_transitions': <torchtext.datasets.nli.ShiftReduceField object at 0x7fc84a575518>, 'hypothesis': <torchtext.datasets.nli.ParsedTextField object at 0x7fc84a575550>, 'hypothesis_transitions': <torchtext.datasets.nli.ShiftReduceField object at 0x7fc84a575518>, 'label': <torchtext.data.field.LabelField object at 0x7fc84a5756a0>}\n","Number of examples:\n"," 549367\n","First Example instance:\n"," {'premise': ['A', 'person', 'on', 'a', 'horse', 'jumps', 'over', 'a', 'broken', 'down', 'airplane', '.'], 'premise_transitions': ['shift', 'shift', 'reduce', 'shift', 'shift', 'shift', 'reduce', 'reduce', 'reduce', 'shift', 'shift', 'shift', 'shift', 'shift', 'shift', 'reduce', 'reduce', 'reduce', 'reduce', 'reduce', 'shift', 'reduce', 'reduce'], 'hypothesis': ['A', 'person', 'is', 'training', 'his', 'horse', 'for', 'a', 'competition', '.'], 'hypothesis_transitions': ['shift', 'shift', 'reduce', 'shift', 'shift', 'shift', 'shift', 'reduce', 'reduce', 'shift', 'shift', 'shift', 'reduce', 'reduce', 'reduce', 'reduce', 'shift', 'reduce', 'reduce'], 'label': 'neutral'}\n","Test iters function\n","Numericalize premises:\n"," (tensor([[   4,    4,   58,  ...,    4,  220,    4],\n","        [  15,    8,    9,  ...,    8, 1699,   24],\n","        [   6,    5,    3,  ...,   13,   16,  155],\n","        ...,\n","        [   1,    1,    1,  ...,    1,   94,    1],\n","        [   1,    1,    1,  ...,    1,    2,    1],\n","        [   1,    1,    1,  ...,    1,    1,    1]]), tensor([ 8, 15,  9, 11, 21, 13,  9, 20, 18,  9, 12, 22, 12, 14, 12, 15, 12, 15,\n","        19, 18, 21, 13, 14, 19, 23, 11, 11, 12, 16,  7, 13, 27, 22, 19, 14, 24,\n","        12, 16, 16, 16, 15, 13,  9, 12, 12, 11, 16, 27, 10, 15, 23, 10, 17, 10,\n","        13,  8, 16, 15, 12, 19, 17, 14, 31, 13]))\n","Numericalize hypotheses:\n"," (tensor([[  4,   4,  58,  ...,  20,  14,  14],\n","        [120,   8,  11,  ...,  19,  30,  24],\n","        [  6,   5, 287,  ..., 360,  11,  96],\n","        ...,\n","        [  1,   1,   1,  ...,   1,   1,   1],\n","        [  1,   1,   1,  ...,   1,   1,   1],\n","        [  1,   1,   1,  ...,   1,   1,   1]]), tensor([ 7, 10,  8,  6, 16,  7,  3, 10,  9, 10,  9, 14,  8, 11, 12, 11,  9, 12,\n","        10,  8, 10,  8,  9, 11,  6, 11, 10, 10,  9,  5,  8, 17, 12, 12,  7,  8,\n","         9, 10, 10,  6, 12, 10,  8,  8, 11,  6,  5, 15, 11,  8, 15,  9,  9, 13,\n","        11,  6,  7, 21,  7, 10,  9,  7,  9, 19]))\n","Entailment labels:\n"," tensor([0, 2, 2, 1, 2, 0, 1, 0, 1, 2, 0, 2, 1, 1, 2, 0, 1, 0, 0, 0, 0, 0, 2, 2,\n","        0, 2, 1, 0, 1, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1, 2, 2, 1, 2, 1, 0, 1, 1, 2,\n","        1, 1, 1, 1, 1, 1, 0, 0, 2, 2, 0, 0, 0, 0, 0, 1])\n"],"name":"stdout"}]},{"metadata":{"id":"O-oY6xkWyGmh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":252},"outputId":"34d91db9-bef4-4d82-a50a-7658807d05a8","executionInfo":{"status":"ok","timestamp":1546451769952,"user_tz":-60,"elapsed":52380,"user":{"displayName":"Uppahhh","photoUrl":"","userId":"09355873330880409745"}}},"cell_type":"code","source":["embedding_dim = TEXT.vocab.vectors.size()[1]\n","num_embeddings = TEXT.vocab.vectors.size()[0]\n","num_classes = len(LABEL.vocab.itos)\n","\n","dropout_rate = 0.4\n","\n","input_dim = 100\n","\n","con_dim = 200\n","\n","hidden_dim = 300\n","\n","\n","# build the model\n","class BCNNet(nn.Module):\n","\n","    def __init__(self):\n","        super(BCNNet, self).__init__()\n","        self.embeddings = nn.Embedding(num_embeddings, embedding_dim)\n","        # use pretrained embeddings\n","        self.embeddings.weight.data.copy_(TEXT.vocab.vectors)\n","        \n","        # The ReLu activtion layer\n","        self.input = Linear(in_features = embedding_dim,\n","                            out_features = embedding_dim,\n","                             bias = False)\n","        \n","        # bilstm encoder\n","        self.bilstm_enc = nn.LSTM(input_size = embedding_dim,\n","                                  hidden_size = embedding_dim,\n","                                  batch_first = False,\n","                                  bidirectional = True)\n","        \n","        # bilstm integrator\n","        self.bilstm_int = nn.LSTM(input_size = embedding_dim*3*2,\n","                                  hidden_size = embedding_dim,\n","                                  batch_first = False,\n","                                  bidirectional = True)\n","        \n","        self.attnx = Linear(in_features=embedding_dim*2,\n","                              out_features = embedding_dim*2)\n","        self.attny = Linear(in_features=embedding_dim*2,\n","                              out_features = embedding_dim*2)\n","        \n","        #Pooling\n","        self.maxpool = nn.MaxPool1d(kernel_size = embedding_dim)\n","        self.avgpool = nn.AvgPool1d(kernel_size = embedding_dim)\n","                \n","        # maxout layer  \n","        self.batch = nn.BatchNorm1d(num_features=8)\n","        \n","        self.maxout = Linear(in_features = 8,\n","                                out_features = 8*2*2)\n","        \n","        \n","        self.mo1 = Maxout.apply\n","        self.mo2 = Maxout.apply\n","        self.mo3 = Maxout.apply\n","        \n","        self.out = Linear(in_features = 8,\n","                            out_features = num_classes,\n","                             bias = False)\n","\n","        self.drop = nn.Dropout(p = dropout_rate)\n","        \n","    def forward(self, x, y):\n","        out = {}\n","        x_text, x_len = x\n","        y_text, y_len = y\n","        \n","        # Sorting tensors\n","        x_len, idx_sort = np.sort(x_len)[::-1],np.argsort(-x_len)\n","        x_text = x_text.index_select(1,torch.LongTensor(idx_sort))\n","        y_len, idx_sort = np.sort(y_len)[::-1],np.argsort(-y_len)\n","        y_text = y_text.index_select(1,torch.LongTensor(idx_sort))\n","        \n","        # Embedding\n","        x = self.embeddings(x_text) # 3, 3, 300\n","        y = self.embeddings(y_text)\n","        \n","        # Relu\n","        x = relu(self.input(x))\n","        y = relu(self.input(y))\n","\n","        # Encoder\n","        packed_x = pack(x,x_len.copy(), batch_first = False)\n","        packed_y = pack(y,y_len.copy(), batch_first = False)\n","        # biLSTM\n","        x, hidenc_fx = self.bilstm_enc(x)\n","        y, hidenc_fy = self.bilstm_enc(y)\n","        xt = hidenc_fx[0]\n","        yt = hidenc_fy[0]\n","        # Unsorting\n","        idx_unsort = np.argsort(idx_sort)\n","        xt1 = xt[0].index_select(0,torch.LongTensor(idx_unsort))\n","        xt2 = xt[1].index_select(0,torch.LongTensor(idx_unsort))\n","\n","        yt1 = yt[0].index_select(0,torch.LongTensor(idx_unsort))\n","        yt2 = yt[1].index_select(0,torch.LongTensor(idx_unsort))\n","\n","        X = torch.cat((xt1,xt2),1) # 1, 3, 600\n","        Y = torch.cat((yt1,yt2),1)\n","        X = X.view(1,X.size()[0],X.size()[1])\n","        Y = Y.view(1,Y.size()[0],Y.size()[1])\n","\n","        \n","        # Biattention\n","        A = torch.matmul(X, Y.transpose(1,2)) # A = X * Y^T  x = bs, len, dim, y^T = bs,dim, len\n","        A_x = softmax(A, dim=2) # A_x = softmax(A)\n","        A_y = softmax(A.transpose(1,2), dim=2) # A_y = softmax(A^T)\n","        C_x = torch.matmul(A_x.transpose(1,2), X) # C_x = A_x^T * X \n","        C_y = torch.matmul(A_y.transpose(1,2), Y) # C_y = A_y^T * Y\n","        \n","        # Integrator\n","        # input for integrator bilstm\n","        \n","        x = torch.cat((X, X-C_y, torch.mul(X, C_y)), 2) # Concat([X; X-C_y; X.C_y])\n","        y = torch.cat((Y, Y-C_x, torch.mul(Y, C_x)), 2) # Concat([Y; Y-C_x; Y.C_x]\n","        \n","            \n","        X_y, hidint_x = self.bilstm_int(x)\n","        Y_x, hidint_y = self.bilstm_int(y)\n","        \n","        X_temp = hidint_x[0]\n","        X_temp = torch.cat((X_temp[0],X_temp[1]),1)\n","        hidint_x = X_temp.view(1,X_temp.size()[0],X_temp.size()[1])\n","        \n","        Y_temp = hidint_y[0]\n","        Y_temp = torch.cat((Y_temp[0],Y_temp[1]),1)\n","        hidint_y = Y_temp.view(1,Y_temp.size()[0],Y_temp.size()[1])\n","       \n","        X_y = hidint_x\n","        Y_x = hidint_y\n","        \n","        \n","        # Pooling\n","        x_maxpool = self.maxpool(X_y)\n","        x_meanpool = self.avgpool(X_y)      \n","        x_minpool = X_y * -1\n","        x_minpool = self.maxpool(x_minpool)\n","        x_minpool = x_minpool * -1\n","        x_pool = torch.cat((x_maxpool, x_meanpool), 2)\n","        \n","        y_maxpool = self.maxpool(Y_x)\n","        y_meanpool = self.avgpool(Y_x)\n","        y_minpool = Y_x * -1\n","        y_minpool = self.maxpool(y_minpool)\n","        y_minpool = y_minpool * -1\n","        y_pool = torch.cat((y_maxpool, y_meanpool), 2)\n","        \n","        # Maxout layer\n","        # With dropout and batchnormilization\n","        # Joined representations is the concatination of x_pool and y_pool\n","        joined = torch.cat((x_pool, y_pool), 2)\n","        joined = torch.squeeze(joined,0)\n","\n","        joined = self.mo1(self.maxout(joined))\n"," \n","        joined = self.mo2(self.maxout(joined))\n","        \n","        joined = self.mo3(self.maxout(joined))\n","        joined = self.batch(joined)\n","        \n","        # 3rd maxout layer will be output\n","        out['out'] = softmax(self.out(joined), dim=1)\n","        return out\n","\n","net = BCNNet()\n","print(net)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["BCNNet(\n","  (embeddings): Embedding(42392, 300)\n","  (input): Linear(in_features=300, out_features=300, bias=False)\n","  (bilstm_enc): LSTM(300, 300, bidirectional=True)\n","  (bilstm_int): LSTM(1800, 300, bidirectional=True)\n","  (attnx): Linear(in_features=600, out_features=600, bias=True)\n","  (attny): Linear(in_features=600, out_features=600, bias=True)\n","  (maxpool): MaxPool1d(kernel_size=300, stride=300, padding=0, dilation=1, ceil_mode=False)\n","  (avgpool): AvgPool1d(kernel_size=(300,), stride=(300,), padding=(0,))\n","  (batch): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (maxout): Linear(in_features=8, out_features=32, bias=True)\n","  (out): Linear(in_features=8, out_features=3, bias=False)\n","  (drop): Dropout(p=0.4)\n",")\n"],"name":"stdout"}]},{"metadata":{"id":"aWHQ-Kk6yGml","colab_type":"code","colab":{}},"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(), lr=0.003,amsgrad=True,weight_decay=0.00001)\n","\n","def accuracy(ys, ts):\n","    # making a one-hot encoded vector of correct (1) and incorrect (0) predictions\n","    correct_prediction = torch.eq(torch.max(ys, 1)[1], ts)\n","    # averaging the one-hot encoded vector\n","    return torch.mean(correct_prediction.float())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_DDja1KHyGmn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e4b84922-79e5-4f51-df66-733bb8dbe1aa"},"cell_type":"code","source":["eval_every = 1000\n","log_every = 200\n","\n","train_loss, train_accs, train_iter_list = [], [], []\n","train_loss_list, train_accs_list = [],[]\n","val_loss_list, val_accs_list, val_iter_list = [],[], []\n","\n","\n","max_acc = 0\n","max_acc_idx = 0\n","epochs = 1\n","reached_max = False\n","\n","net.train()\n","while epochs <= 5:\n","    print(\"EPOCH NR: \" + str(epochs))\n","    for i, batch in enumerate(train_iter):\n","        if i % eval_every == 0:\n","            net.eval()\n","            val_losses, val_accs, val_lengths = 0, 0, 0\n","      #  val_meta = {'label_idx': [], 'sentences': [], 'labels': []}\n","            for val_batch in val_iter:\n","                output = net(val_batch.premise,val_batch.hypothesis)\n","            # batches sizes might vary, which is why we cannot just mean the batch's loss\n","            # we multiply the loss and accuracies with the batch's size,\n","            # to later divide by the total size\n","                val_losses += criterion(output['out'], val_batch.label) * val_batch.batch_size\n","                val_accs += accuracy(output['out'], val_batch.label) * val_batch.batch_size\n","                val_lengths += val_batch.batch_size\n","            \n","\n","        \n","        # divide by the total accumulated batch sizes\n","            val_losses /= val_lengths\n","            val_accs /= val_lengths\n","        \n","            val_loss_list.append(get_numpy(val_losses))\n","            val_accs_list.append(get_numpy(val_accs))\n","            val_iter_list.append(i)\n","        \n","            print(\"valid, it: {} loss: {:.2f} accs: {:.2f}\\n\".format(i, get_numpy(val_losses), get_numpy(val_accs)))\n","        #update_plot(val_meta, 'bow', tsne_plot)\n","        \n","            net.train()\n","    \n","        output = net(batch.premise,batch.hypothesis)\n","        batch_loss = criterion(output['out'], batch.label)\n","    \n","        train_loss.append(get_numpy(batch_loss))\n","        train_accs.append(get_numpy(accuracy(output['out'], batch.label)))\n"," \n","    \n","        optimizer.zero_grad()\n","        batch_loss.backward()\n","        nn.utils.clip_grad_norm_(net.parameters(),max_norm=5)\n","        optimizer.step()\n","    \n","        if i % log_every == 0:        \n","            print(\"train, it: {} loss: {:.2f} accs: {:.2f}\".format(i, \n","                                                               np.mean(train_loss), \n","                                                               np.mean(train_accs)))\n","        # reset\n","            train_loss_list.append(np.mean(train_loss))\n","            train_accs_list.append(np.mean(train_accs))    \n","            train_iter_list.append(i)\n","            train_loss, train_accs = [], []\n","    if max(val_accs_list[max_acc_idx:len(val_accs_list)]) > max_acc:\n","        max_acc = max(val_accs_list[max_acc_idx:len(val_accs_list)])\n","        max_acc_idx = np.argmax(max(val_accs_list[max_acc_idx:len(val_accs_list)]))\n","    else:\n","        print(\"Maximum validation accuracy: \" + str(max_acc))\n","        reached_max = True\n","        break\n","    epochs += 1\n","        "],"execution_count":0,"outputs":[{"output_type":"stream","text":["EPOCH NR: 1\n"],"name":"stdout"}]},{"metadata":{"id":"nPMz8pOjKiql","colab_type":"code","colab":{}},"cell_type":"code","source":["for i in range(int(len(train_iter_list)/(epochs)),len(train_iter_list)):\n","    if train_iter_list[i] == 0:\n","        train_iter_list[i] = train_iter_list[i-1]+1\n","        continue\n","    else:\n","        train_iter_list[i] = train_iter_list[i-1] + log_every\n","\n","\n","for i in range(int(len(val_iter_list)/epochs),len(val_iter_list)):\n","    if val_iter_list[i] == 0:\n","        val_iter_list[i] =val_iter_list[i-1]+1\n","        continue\n","    else:\n","        val_iter_list[i] = val_iter_list[i-1] + eval_every"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PuxtuUO1yGmq","colab_type":"code","colab":{}},"cell_type":"code","source":["fig = plt.figure(figsize=(12,4))\n","plt.subplot(1, 2, 1)\n","plt.plot(train_iter_list, train_loss_list, label='train_loss')\n","plt.plot(val_iter_list, val_loss_list, label='valid_loss')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(train_iter_list, train_accs_list, label='train_accs')\n","plt.plot(val_iter_list, val_accs_list, label='valid_accs')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"h9sZLlz7p-oF","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}